{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.functional import normalize\n",
    "from pandas import DataFrame\n",
    "from datetime import datetime\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sql\n",
    "%config SqlMagic.style = '_DEPRECATED_DEFAULT'\n",
    "%config SqlMagic.autopandas = True\n",
    "%sql postgresql+psycopg://admin:admin@localhost:5432/buses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    ")\n",
    "\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_data_from_db(line_name: int, optional_direction: str | int):\n",
    "    if isinstance(optional_direction, str): \n",
    "        res = %sql SELECT id FROM public.directions WHERE value = :optional_direction\n",
    "        direction_id = res[0][0]\n",
    "    else:\n",
    "        direction_id = optional_direction\n",
    "    records = %sql SELECT course_loid, day_course_loid, longitude, latitude, angle, reached_meters, order_in_course, last_ping_date FROM \\\n",
    "                public.positions WHERE optional_direction = :direction_id AND line_name = :line_name\n",
    "    return records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_objects(data: DataFrame) -> torch.Tensor:\n",
    "    parsed_x = []\n",
    "    parsed_y = []\n",
    "    courses = {}\n",
    "    counter = 0\n",
    "    for _, row in data.iterrows():\n",
    "        counter += 1\n",
    "        if counter % 10000 == 0:\n",
    "            print(f\"Parsed {counter}\")\n",
    "        if row.course_loid not in courses:\n",
    "            courses[row.course_loid] = requests.get(\n",
    "                f\"https://przystanki.bialystok.pl/portal/getRealCourse.json?courseId={int(row.course_loid)}\"\n",
    "            ).json()\n",
    "        predicted_stop_point = (\n",
    "            (row.order_in_course + 1)\n",
    "            if data[\n",
    "                (\n",
    "                    (data[\"day_course_loid\"] == row.day_course_loid)\n",
    "                    & (data[\"order_in_course\"] == (row.order_in_course + 1))\n",
    "                )\n",
    "            ]\n",
    "            .any()\n",
    "            .any()\n",
    "            else row.order_in_course\n",
    "        )\n",
    "        dt = datetime.fromtimestamp(row.last_ping_date / 1000)\n",
    "        time = dt.hour * 3600 + dt.minute * 60 + dt.second\n",
    "        arrived_dt = datetime.fromtimestamp(\n",
    "            data[\n",
    "                (\n",
    "                    (data[\"day_course_loid\"] == row.day_course_loid)\n",
    "                    & (data[\"order_in_course\"] == predicted_stop_point)\n",
    "                )\n",
    "            ]\n",
    "            .nsmallest(1, \"last_ping_date\")\n",
    "            .last_ping_date.item()\n",
    "            / 1000\n",
    "        )\n",
    "        arrived_time = (\n",
    "            arrived_dt.hour * 3600 + arrived_dt.minute * 60 + arrived_dt.second\n",
    "        )\n",
    "        parsed_x.append(\n",
    "                [\n",
    "                    row.longitude,\n",
    "                    row.latitude,\n",
    "                    float(row.angle),\n",
    "                    float(row.reached_meters),\n",
    "                    float(row.order_in_course),\n",
    "                    time,\n",
    "                    [\n",
    "                        stop[\"scheduledDepartureSec\"]\n",
    "                        for stop in courses[row.course_loid][\"realCourse\"][\"stoppings\"]\n",
    "                        if stop[\"orderInCourse\"] == predicted_stop_point\n",
    "                    ][0],\n",
    "                    predicted_stop_point,\n",
    "                ]\n",
    "        )\n",
    "        parsed_y.append([arrived_time])\n",
    "    \n",
    "    parsed_x = normalize(torch.tensor(parsed_x, dtype=torch.float32, device=\"cuda\"))\n",
    "    parsed_y = torch.tensor(parsed_y, dtype=torch.float32, device=\"cuda\")\n",
    "\n",
    "    \n",
    "    return zip(parsed_x, parsed_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(\n",
    "    nn.Linear(8, 256), \n",
    "    nn.Dropout(0.2),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(256, 128),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(128, 64),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(64, 32),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(32, 1),\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataset, num_epochs=100, batch_size=32, learning_rate=0.001):\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    criterion = nn.MSELoss()  # Użycie MSE, jeśli Y jest wartością ciągłą\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for inputs, targets in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            optimizer.zero_grad()  # Zerowanie gradientów\n",
    "            outputs = model(inputs)  # Forward pass\n",
    "            loss = criterion(outputs.squeeze(), targets)  # Obliczanie straty\n",
    "            loss.backward()  # Backward pass\n",
    "            optimizer.step()  # Aktualizacja wag\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_model_data_from_db(100, 12282)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared = prepare_objects(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_zipped = list(prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(net, prepared)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scraper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
